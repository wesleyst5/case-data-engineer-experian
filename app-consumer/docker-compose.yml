version: '3.4'

x-common:
  &common
  build: .
  volumes:
    - dados-datalake:/datalake
  networks:
    - airflow-network

services:
  spark-master:
    #image: app-consumer-spark:latest
    <<: [ *common]
    container_name: app-consumer-spark
    networks:
      - default
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
    ports:
      - 8080:8080
      - 7077:7077
    command: /opt/spark-3.3.2-bin-hadoop3/bin/spark-class org.apache.spark.deploy.master.Master

  spark-worker:
    #image: app-consumer-spark:latest
    <<: [ *common ]
    container_name: app-consumer-spark-worker
    networks:
      - default
    depends_on:
      - spark-master
    environment:
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_HOSTNAME=spark-worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    command: /opt/spark-3.3.2-bin-hadoop3/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

networks:
  default:
    external:
      name: external-network
volumes:
  dados-datalake:
    external: true